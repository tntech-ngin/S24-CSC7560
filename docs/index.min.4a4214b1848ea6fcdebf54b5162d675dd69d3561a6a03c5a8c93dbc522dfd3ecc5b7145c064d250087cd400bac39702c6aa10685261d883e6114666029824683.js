var suggestions=document.getElementById("suggestions"),search=document.getElementById("search");search!==null&&document.addEventListener("keydown",inputFocus);function inputFocus(e){e.ctrlKey&&e.key==="/"&&(e.preventDefault(),search.focus()),e.key==="Escape"&&(search.blur(),suggestions.classList.add("d-none"))}document.addEventListener("click",function(e){var t=suggestions.contains(e.target);t||suggestions.classList.add("d-none")}),document.addEventListener("keydown",suggestionFocus);function suggestionFocus(e){const s=suggestions.classList.contains("d-none");if(s)return;const t=[...suggestions.querySelectorAll("a")];if(t.length===0)return;const n=t.indexOf(document.activeElement);if(e.key==="ArrowUp"){e.preventDefault();const s=n>0?n-1:0;t[s].focus()}else if(e.key==="ArrowDown"){e.preventDefault();const s=n+1<t.length?n+1:n;t[s].focus()}}(function(){var e=new FlexSearch.Document({tokenize:"forward",cache:100,document:{id:"id",store:["href","title","description"],index:["title","description","content"]}});e.add({id:0,href:"/S24-CSC7560/docs/prologue/schedule/",title:"Schedule",description:`This is a tentative schedule and will change.
Grading details #Assessment Type Weightage Additional Information Presentations and Discussions 40% Programming Assignments 50% Class Participation 10% Class Schedule #Overview #Overview of the rest of the semester Lecture Initial Presentations #Traffic Prediction #Tuesday, Feb 27:
Paper 1 Paper 1: AI/ML-based real-time classification of Software Defined Networking traffic Link Slides Discussion Notes Speaker: Yoshi Slides Questions: Q1: In section 3.`,content:`This is a tentative schedule and will change.
Grading details #Assessment Type Weightage Additional Information Presentations and Discussions 40% Programming Assignments 50% Class Participation 10% Class Schedule #Overview #Overview of the rest of the semester Lecture Initial Presentations #Traffic Prediction #Tuesday, Feb 27:
Paper 1 Paper 1: AI/ML-based real-time classification of Software Defined Networking traffic Link Slides Discussion Notes Speaker: Yoshi Slides Questions: Q1: In section 3.3 what does delta packets, instant bytes per seconds and instant packets per second features mean? Q2: What are the preprocessing steps in this study? Q3: What are the applications/benefits of categorizing the traffic? Q4: How do the Machine Learning algorithms compare with state-of-the-art traditional algorithms for SDN traffic classification? Q5: what are the tradeoffs to each of the supervised learning algorithms and how to they apply to a specific network scenario? Q6: Is it real- time? How can we measure that it is actual real-time? Q7: The data was divided into four categories, but is there any indication of what most influenced those categories? Q8: Does the report offer any explanation for the telnet misclassifying for the LR and Naive Bayes and/or did they offer any insight on what could be improved upon for better results? How do the Machine Learning algorithms compare with state-of-the-art traditional algorithms for SDN traffic classification? In section 3.3 what does delta packets, instant bytes per seconds and instant packets per second features mean? What are the applications/benefits of categorizing the traffic? Thursday, Feb 29:
Code Review Tuesday, Mar 5:
Paper 2 Predicting Future Traffic using Hidden Markov Models Link Slides Discussion Notes Speaker: Jestus Slides Questions: Predicting Future Traffic using Hidden Markov Models - What is the extent of the state the Markov State is encapsulating? Why is it expensive to directly capture traffic. And, what their definition of a flow count, and how is collecting that easier than collecting traffic volume? What are the trade offs to each supevised learning alg. and how do each apply to the scenario? My understanding of Markov property is future state depends only on the current state. So, for predicting flow volume in network, does this assumption hold in real world scenarios of network? How is KBR related to HMM? Why is it expensive to directly capture traffic. And, what is their definition of a flow count, and how is collecting that easier than collecting traffic volume? Paper 3	Flow-based Throughput Prediction using Deep Learning and Real-World Network Traffic Link Slides Discussion Notes Speaker: Nick Slides Questions: Q1: Given that the paper tries to predict bit rate of network traffic flow, I\u0026rsquo;d like to understand why this is treated as a classification task and not as a regression task. What are the advantages to this approach? Compare both binary classification and multi-class classification, what are the advantages of using multi-class classification? What is the output, a number representing bitrate or a class attribute? Can the model be helpfully accurate when predicting continuous variables? Why are some features better than others? What are the scatter plot cluster supposed to demonstrate ? Why are bit rate informed routing discissions going to be better than what is currently present ? How do you expect these developments to effect routing efficiency? Will performance gains be enough to justify the over head of the proposal? What is are the anticipated impacts of the model not considering the longest lasting flows (those greater than 5mins)? I would think these would have the highest impact on resources utilization. How close are the inaccurate predictions ? Are only flow features ( like 5-tuple described in paper) enough for Throughput prediction? Can we use this model in dynamic network conditions if we include topology information as additional features? Given that the paper tries to predict bit rate of network traffic flow, I\u0026rsquo;d like to understand why this is treated as a classification task and not as a regression task. What are the advantages to this approach? The paper mentions quantizing bitrates into three classes instead of the common \u0026ldquo;mice\u0026rdquo; and \u0026ldquo;elephant\u0026rdquo; flow binary classification. why these three classes are chosen? Traffic Classification #Thursday, Mar 7:
Paper 4 Resource Management with Deep Reinforcement Learning Link Slides Speaker: Rajat Slides Questions: Is it possible to apply this approach for non-preemptive scheduling? Is it possible to use this approach for real-time jobs since it is based on reinforcement learning and learn online from environment? What are the computational and resource requirements for training and deploying the DeepRM model in a real-world cluster environment, and how do they scale with the size and complexity of the cluster and workload? What are some potential problems that can arise if Deep RN were to be deployed on a real-world network instead of a pre-constructed network for it to train? What is the difference between Completion Time (Cj) and duration (Tj) of the job? How does DeepRM handle scenarios where resources are dynamically changing or where resource demands fluctuate over time? Is there any indication in this paper of issues scaling this trained network into a larger system? What is are the anticipated impacts of the model not considering the longest lasting flows (those greater than 5mins)? I would think these would have the highest impact on resources utilization. How can we leverage Deep RL techniques to automatically learn efficient resource management in complex computer systems and networks? What are some potential problems that can arise if Deep RN were to be deployed on a real-world network instead of a pre-constructed network for it to train? What are the impacts on wait times for longer jobs that are withheld? is this a fair system? When does the actual jobs get run and how does that feedback get sent to the scheduler? Are there advantages to continuously training the algorithm? What other things can you train the reinforcement algorithm on? Would the algorithm do better if it were seated with a high performance scheduler to start and then reinforce based on that? Paper 5 Selecting critical features for data classification based on machine learning methods Link Slides Speaker: Xi Slides Questions: What are Po and Pe in equation 9? How much do the feature selections depend on model trying to predict? Can we combine feature selection methods based on the model we want to preprocess for better performance? Considering the significant variation in accuracy observed across different feature selection methods (RF, RFE, Boruta) and classifier algorithms (RF, SVM, KNN, LDA), what can we infer, and when would an algorithm be preferred in a real-world scenario? Is the importance of features derived from machine learning algorithms consistent across all target classes of classification task? Some features can be more important for predicting one class than another. What impact does this have on the feature selection process? compare both binary classification and multi-class classification, what are the advantages of using multi-class classification? Can the feature selection methods handle imbalanced datasets effectively? Selecting critical features for data classification based on machine learning methods: What peculiarities of the dataset might have influenced the performance of one methodology or another? Is there ever a time to use the lower preforming algorithms ? The paper assumes that the relationship between flow counts and traffic volumes, modeled by the transition and emission probabilities in the HMM, does it remain stationary over time? What is the time saving we get from applying these algorithms ? Is there ever a time to use the lower preforming? algorithms What is the time saving we get from applying these algorithms Is there ever a time to use the lower preforming algorithms Thursday, Mar 19:
Paper 6 A general approach for traffic classification in wireless networks using deep learning Link Slides Speaker: Jacob Slides Questions: Is there any bias for the CNN model, and if so where is it occurring? When is trading time complexity for a higher accuracy worth it in a real-time implementation? A General Approach for Traffic Classification in Wireless Networks Using Deep Learning: It looks like they used three models that does very related tasks: for example: one classifies if the packet is data or others, second classifies if it is a video or others and third if it is one of the video apps or others. Can multi-task learning model be used here to train one model that does all these tasks at once? How does the performance of the proposed Traffic Classification (TC) framework change under different Signal-to-Noise Ratio (SNR) conditions? What are the preprocessing steps for the data collection step in the traffic classification system using spectrum data? Most of the wireless categories that the paper noted as classifiers were for entertainment applications. Why might these specific classifiers been used? How can we leverage deep learning techniques directly on raw spectrum data in complex wireless network environments? How does the performance of the proposed Traffic Classification (TC) framework change under different Signal-to-Noise Ratio (SNR) conditions? What are the preprocessing steps for the data collection step in the traffic classification system using spectrum data? Most of the wireless categories that the paper noted as classifiers were for entertainment applications. Why might these specific classifiers been used? Why is CNN so good at classifying signals. Are there other ML modules that could be similarly leveraged? Are there other signals that can be leveraged for classification using this methodology? (Heart Rate, Light etc. ) How can we leverage deep learning techniques directly on raw spectrum data in complex wireless network environments? What are the authors\u0026rsquo; plans for using the three models\u0026rsquo; results Paper 7 Pilot-Edge: Distributed Resource Management Along the Edge-to-Cloud Continuum Link Slides Speaker: Sepideh Slides Questions: Based on the experimental results, what are some trade-offs that need to be considered when deploying machine learning models in edge-to-cloud environments? How can these trade-offs be optimized for better performance? Pilot-Edge: Distributed Resource Management Along the Edge-to-Cloud Continuum : How does the Pilot-Edge support dynamism of resources: expanding and scaling down dynamically at runtime? Does it depend on Dask or has its own mechanism? Why did the researchers decide to go with the auto-encoder, isolation forests, and k-means models over other machine learning models? Considering the use case of Pilot-Edge is to distribute resource usage across available devices, why is there a significant distinction made between an edge device and a cloud, when both are made of distinct devices, even if they are geographically distinct? How can we design an framework for IoT applications, especially those involving heterogeneous machine learning tasks? I understand that mobile devices act as edge devices in the edge-to-cloud continuum. For data generated on mobile phones, how does Pilot-Edge determine whether to process this data locally or offload the task based on the processing task\u0026rsquo;s complexity? Does this require installing an agent on the mobile phones, or is there another method of implementation? Why did the researchers decide to go with the auto-encoder, isolation forests, and k-means models over other machine learning models? Considering the use case of Pilot-Edge is to distribute resource usage across available devices, why is there a significant distinction made between an edge device and a cloud, when both are made of distinct devices, even if they are geographically distinct? What are examples of specific applications for this system? The conclusion mentions the future integration of other layer types, what are examples of these layers and when would they bee needed? Could this model me leveraged for offline applications, (iot devices and locally accessible recourses stores)? I have a hard time seeing the direct ML implications of this paper (aside for just allowing ML applications to be accessed via cloud by IoT applications) can you further explain them? How can we design an framework for IoT applications, especially those involving heterogeneous machine learning tasks? Resource management #Thursday, Mar 21:
Paper 8 Detection and Classification of Botnet Traffic using Deep Learning with Model Explanation Link Slides Speaker: Jonathan Slides Questions: How does pretraining CNN on unlabelled data and retraining on labelled data work? (Section II A 3rd paragraph) How does Multi-Task Learning (MTL) work? Is it just a term for a ML model that has more than one target variable? Does the radio network stack align with the internet\u0026rsquo;s 4 layer architecture, with the link layer being the only difference? To create dataset, the paper uses MATLAB WLAN toolbox to generate L1 waveforms from L2 pcap files. What are the advantages to this approach compared to capturing L1 traffic directly? Does this paper consider data privacy and ethic in training model? How can me make this approach more efficient in terms of scalability? How could the synthetic dataset generate better data for this task? Based on the findings of this study, what are some potential avenues for future research in the field of botnet detection and classification? The paper talks about the importance of model interpretability along with learning the model. Can there be trade-offs between model performance to accurately detect and classify botnet traffic and model interpretability? What are the feature extraction process from network traffic for botnet classification? The paper did not talk about it very well. What constitues a sample in the dataset / What are the features? The paper states that the feature extraction module extracts 199 features. Why is it better for making the resource central an independent and general system that is off the critical performance and availability paths of the systems that use it? Why was architecture 12, an approach which had a high but not the highest F1-Score, chosen? Were their advantages to choosing another architecture, such as 11? Can this be used to classify other types of flows like ransomware? Can this be adapted to be used online as a IDS ? How the deep learning techniques classify botnet traffic in real-world network environments? Question2: How can me make this approach more efficient in terms of scalability?
\u0026lt;details\u0026gt; \u0026lt;summary\u0026gt;Paper 9\u0026lt;/summary\u0026gt; - Resource Central: Understanding and Predicting Workloads for Improved Resource Management in Large Cloud Platforms[Link](https://dl.acm.org/doi/pdf/10.1145/3132747.3132772) [Slides](https://docs.google.com/presentation/d/17dMuEX3PDFOoG8JycPVkCcqFcC2XHNBA/edit?usp=drive_link\u0026amp;ouid=100211778554961279713\u0026amp;rtpof=true\u0026amp;sd=true) - Speaker: Zach - [Slides](#) - Questions: - Can workload prediction model be generalized across different cloud platform? - How can workload prediction models be merged or extended to the cloud services? - Where the metrics outcomes for the models considered good enough for implementation in a real-time network, or are higher metrics required? - The dataset used in the paper contains information of VMs of just 3 months. However, cloud environments are dynamic that can change in workload patterns, resources, and system configurations. How to make sure Resource Central can adapt to such changes and provide long term predictions? - In what ways can accurate predictions of VM behavior improve the performance and reliability of cloud services? - The \u0026quot;smart power oversubscription and capping\u0026quot; in page 8 implies that some VMs batch and background tasks would lose significant computational power. Isn't this unethical, given that the customer has already paid for these VMs via subscrition? - Does the paper imply that large cloud platforms trend towards similar utilizations of Virtual Machines, such that predicting them becomes simpler using the paper's approach? If not, then how does the approach accommodate for differing services beyond retraining the model for each large cloud platform? - Understanding and Predicting Workloads for Improved Resource: Management in Large Cloud Platforms: What are the key characteristics and patterns of VM workloads be learned and predicted more efficient? TBD #Tuesday, Mar 26:
Papers Paper 1: [Title] Link Speaker: [Speaker Name] Slides Questions: Q1: Thursday, Mar 28:
Papers Paper 1: [Title] Link Speaker: [Speaker Name] Slides Questions: Q1: Tuesday, Apr 2:
Papers Paper 1: [Title] Link Speaker: [Speaker Name] Slides Questions: Q1: Thursday, Apr 4:
Papers Paper 1: [Title] Link Speaker: [Speaker Name] Slides Questions: Q1: Tuesday, Apr 9:
Papers Paper 1: [Title] Link Speaker: [Speaker Name] Slides Questions: Q1: Thursday, Apr 11:
Papers Paper 1: [Title] Link Speaker: [Speaker Name] Slides Questions: Q1: Tuesday, Apr 16:
Papers Paper 1: [Title] Link Speaker: [Speaker Name] Slides Questions: Q1: Thursday, Apr 18:
Papers Paper 1: [Title] Link Speaker: [Speaker Name] Slides Questions: Q1: Tuesday, Apr 23:
Papers Paper 1: [Title] Link Speaker: [Speaker Name] Slides Questions: Q1: Thursday, Apr 25:
Papers Paper 1: [Title] Link Speaker: [Speaker Name] Slides Questions: Q1: `}),e.add({id:1,href:"/S24-CSC7560/docs/prologue/",title:"Prologue",description:"Prologue Doks.",content:""}),e.add({id:2,href:"/S24-CSC7560/docs/",title:"Docs",description:"Docs Doks.",content:""}),search.addEventListener("input",t,!0);function t(){const s=5;var n=this.value,o=e.search(n,{limit:s,enrich:!0});const t=new Map;for(const e of o.flatMap(e=>e.result)){if(t.has(e.doc.href))continue;t.set(e.doc.href,e.doc)}if(suggestions.innerHTML="",suggestions.classList.remove("d-none"),t.size===0&&n){const e=document.createElement("div");e.innerHTML=`No results for "<strong>${n}</strong>"`,e.classList.add("suggestion__no-results"),suggestions.appendChild(e);return}for(const[r,a]of t){const n=document.createElement("div");suggestions.appendChild(n);const e=document.createElement("a");e.href=r,n.appendChild(e);const o=document.createElement("span");o.textContent=a.title,o.classList.add("suggestion__title"),e.appendChild(o);const i=document.createElement("span");if(i.textContent=a.description,i.classList.add("suggestion__description"),e.appendChild(i),suggestions.appendChild(n),suggestions.childElementCount==s)break}}})()